{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62094bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from patchify import patchify\n",
    "import PIL\n",
    "from PIL import Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f269c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self,root,target, train=True, transforms=None):\n",
    "        super(PatchDataset, self).__init__()\n",
    "        self.image_path = [os.path.join(root, x) for x in os.listdir(root)]      \n",
    "        self.ref_path = [os.path.join(target,x) for x in os.listdir(target)]\n",
    "        \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "\n",
    "        if train:\n",
    "            self.images = self.image_path[: int(.8 * len(self.image_path))]\n",
    "            self.ref = self.ref_path[: int(.8 * len(self.image_path))]\n",
    "        else:\n",
    "            self.images = self.image_path[int(.8 * len(self.image_path)):]\n",
    "            self.ref = self.ref_path[int(.8 * len(self.image_path)):]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.transform(self.images[item]),self.transform(self.ref[item])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c83bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    lambda x: Image.open(x).convert('RGB'),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "160581b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder_ = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38739d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decoder_ = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bcc4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebbec914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CAE(\n",
      "  (encoder): Encoder(\n",
      "    (encoder_): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): ReLU()\n",
      "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder_): Sequential(\n",
      "      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (7): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CAE().to(device)\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "l1_loss = nn.L1Loss().to(device)\n",
    "Hube = torch.nn.HuberLoss().to(device)\n",
    "CE = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "train_dataset = PatchDataset(\"OS_412(64)_SSIM_BlankRemove\",\"OS_415(64)_SSIM_BlankRemove\",train=True, transforms=transform)\n",
    "test_dataset = PatchDataset(\"OS_412(64)_SSIM_BlankRemove\",\"OS_415(64)_SSIM_BlankRemove\",train=False, transforms=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(device)\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8d9ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unloader = transforms.ToPILImage()\n",
    "def tensor_to_PIL(tensor):\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = unloader(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4912cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.0221\n",
      "Epoch [1/30], Test Loss: 0.0306\n",
      "Epoch [2/30], Train Loss: 0.0214\n",
      "Epoch [2/30], Test Loss: 0.0308\n",
      "Epoch [3/30], Train Loss: 0.0213\n",
      "Epoch [3/30], Test Loss: 0.0305\n",
      "Epoch [4/30], Train Loss: 0.0212\n",
      "Epoch [4/30], Test Loss: 0.0307\n",
      "Epoch [5/30], Train Loss: 0.0211\n",
      "Epoch [5/30], Test Loss: 0.0307\n",
      "Epoch [6/30], Train Loss: 0.0212\n",
      "Epoch [6/30], Test Loss: 0.0306\n",
      "Epoch [7/30], Train Loss: 0.0210\n",
      "Epoch [7/30], Test Loss: 0.0304\n",
      "Epoch [8/30], Train Loss: 0.0209\n",
      "Epoch [8/30], Test Loss: 0.0304\n",
      "Epoch [9/30], Train Loss: 0.0208\n",
      "Epoch [9/30], Test Loss: 0.0304\n",
      "Epoch [10/30], Train Loss: 0.0208\n",
      "Epoch [10/30], Test Loss: 0.0303\n",
      "Epoch [11/30], Train Loss: 0.0208\n",
      "Epoch [11/30], Test Loss: 0.0304\n",
      "Epoch [12/30], Train Loss: 0.0206\n",
      "Epoch [12/30], Test Loss: 0.0303\n",
      "Epoch [13/30], Train Loss: 0.0207\n",
      "Epoch [13/30], Test Loss: 0.0302\n",
      "Epoch [14/30], Train Loss: 0.0207\n",
      "Epoch [14/30], Test Loss: 0.0301\n",
      "Epoch [15/30], Train Loss: 0.0207\n",
      "Epoch [15/30], Test Loss: 0.0300\n",
      "Epoch [16/30], Train Loss: 0.0208\n",
      "Epoch [16/30], Test Loss: 0.0301\n",
      "Epoch [17/30], Train Loss: 0.0208\n",
      "Epoch [17/30], Test Loss: 0.0300\n",
      "Epoch [18/30], Train Loss: 0.0207\n",
      "Epoch [18/30], Test Loss: 0.0299\n",
      "Epoch [19/30], Train Loss: 0.0206\n",
      "Epoch [19/30], Test Loss: 0.0299\n",
      "Epoch [20/30], Train Loss: 0.0205\n",
      "Epoch [20/30], Test Loss: 0.0298\n",
      "Epoch [21/30], Train Loss: 0.0206\n",
      "Epoch [21/30], Test Loss: 0.0297\n",
      "Epoch [22/30], Train Loss: 0.0206\n",
      "Epoch [22/30], Test Loss: 0.0297\n",
      "Epoch [23/30], Train Loss: 0.0210\n",
      "Epoch [23/30], Test Loss: 0.0298\n",
      "Epoch [24/30], Train Loss: 0.0208\n",
      "Epoch [24/30], Test Loss: 0.0298\n",
      "Epoch [25/30], Train Loss: 0.0208\n",
      "Epoch [25/30], Test Loss: 0.0298\n",
      "Epoch [26/30], Train Loss: 0.0207\n",
      "Epoch [26/30], Test Loss: 0.0297\n",
      "Epoch [27/30], Train Loss: 0.0206\n",
      "Epoch [27/30], Test Loss: 0.0296\n",
      "Epoch [28/30], Train Loss: 0.0206\n",
      "Epoch [28/30], Test Loss: 0.0296\n",
      "Epoch [29/30], Train Loss: 0.0203\n",
      "Epoch [29/30], Test Loss: 0.0296\n",
      "Epoch [30/30], Train Loss: 0.0203\n",
      "Epoch [30/30], Test Loss: 0.0295\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    for (inputs,targets) in train_loader:\n",
    "        img = inputs\n",
    "        img = img.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "        outputs = model(img)\n",
    "#         # Compute loss\n",
    "        loss = criterion(outputs, targets).to(device)\n",
    "\n",
    "#         # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (data,targets) in test_loader:\n",
    "            img = data\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            targets = targets.to(device)\n",
    "            loss_test = criterion(outputs, targets).to(device)\n",
    "            \n",
    "            \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {loss_test.item():.4f}')\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(loss_test.item())\n",
    "    # Save the trained model\n",
    "    path = 'CAE_Model(64)_MapLearning/epoch_{i}_MSE.pth'.format(i=epoch+1)\n",
    "    torch.save(model.state_dict(), path)\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3f40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.0100\n",
      "Epoch [1/30], Test Loss: 0.0147\n",
      "Epoch [2/30], Train Loss: 0.0100\n",
      "Epoch [2/30], Test Loss: 0.0146\n",
      "Epoch [3/30], Train Loss: 0.0100\n",
      "Epoch [3/30], Test Loss: 0.0146\n",
      "Epoch [4/30], Train Loss: 0.0100\n",
      "Epoch [4/30], Test Loss: 0.0146\n",
      "Epoch [5/30], Train Loss: 0.0100\n",
      "Epoch [5/30], Test Loss: 0.0146\n",
      "Epoch [6/30], Train Loss: 0.0100\n",
      "Epoch [6/30], Test Loss: 0.0146\n",
      "Epoch [7/30], Train Loss: 0.0101\n",
      "Epoch [7/30], Test Loss: 0.0147\n",
      "Epoch [8/30], Train Loss: 0.0103\n",
      "Epoch [8/30], Test Loss: 0.0147\n",
      "Epoch [9/30], Train Loss: 0.0103\n",
      "Epoch [9/30], Test Loss: 0.0149\n",
      "Epoch [10/30], Train Loss: 0.0102\n",
      "Epoch [10/30], Test Loss: 0.0149\n",
      "Epoch [11/30], Train Loss: 0.0102\n",
      "Epoch [11/30], Test Loss: 0.0149\n",
      "Epoch [12/30], Train Loss: 0.0101\n",
      "Epoch [12/30], Test Loss: 0.0148\n",
      "Epoch [13/30], Train Loss: 0.0100\n",
      "Epoch [13/30], Test Loss: 0.0149\n",
      "Epoch [14/30], Train Loss: 0.0100\n",
      "Epoch [14/30], Test Loss: 0.0148\n",
      "Epoch [15/30], Train Loss: 0.0100\n",
      "Epoch [15/30], Test Loss: 0.0148\n",
      "Epoch [16/30], Train Loss: 0.0100\n",
      "Epoch [16/30], Test Loss: 0.0148\n",
      "Epoch [17/30], Train Loss: 0.0100\n",
      "Epoch [17/30], Test Loss: 0.0148\n",
      "Epoch [18/30], Train Loss: 0.0100\n",
      "Epoch [18/30], Test Loss: 0.0148\n",
      "Epoch [19/30], Train Loss: 0.0100\n",
      "Epoch [19/30], Test Loss: 0.0148\n",
      "Epoch [20/30], Train Loss: 0.0100\n",
      "Epoch [20/30], Test Loss: 0.0148\n",
      "Epoch [21/30], Train Loss: 0.0100\n",
      "Epoch [21/30], Test Loss: 0.0148\n",
      "Epoch [22/30], Train Loss: 0.0100\n",
      "Epoch [22/30], Test Loss: 0.0148\n",
      "Epoch [23/30], Train Loss: 0.0100\n",
      "Epoch [23/30], Test Loss: 0.0148\n",
      "Epoch [24/30], Train Loss: 0.0100\n",
      "Epoch [24/30], Test Loss: 0.0147\n",
      "Epoch [25/30], Train Loss: 0.0100\n",
      "Epoch [25/30], Test Loss: 0.0147\n",
      "Epoch [26/30], Train Loss: 0.0100\n",
      "Epoch [26/30], Test Loss: 0.0148\n",
      "Epoch [27/30], Train Loss: 0.0100\n",
      "Epoch [27/30], Test Loss: 0.0148\n",
      "Epoch [28/30], Train Loss: 0.0100\n",
      "Epoch [28/30], Test Loss: 0.0148\n",
      "Epoch [29/30], Train Loss: 0.0100\n",
      "Epoch [29/30], Test Loss: 0.0148\n",
      "Epoch [30/30], Train Loss: 0.0100\n",
      "Epoch [30/30], Test Loss: 0.0148\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    for (inputs,targets) in train_loader:\n",
    "        img = inputs\n",
    "        img = img.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "        outputs = model(img)\n",
    "#         # Compute loss\n",
    "        loss = Hube(outputs, targets).to(device)\n",
    "\n",
    "#         # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (data,targets) in test_loader:\n",
    "            img = data\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            targets = targets.to(device)\n",
    "            loss_test = Hube(outputs, targets).to(device)\n",
    "            \n",
    "            \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {loss_test.item():.4f}')\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(loss_test.item())\n",
    "    # Save the trained model\n",
    "    path = 'CAE_Model(64)_MapLearning/epoch_{i}_HUBER.pth'.format(i=epoch+1)\n",
    "    torch.save(model.state_dict(), path)\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d9a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(\"E:\\PG_HP_FINAL\\CAE Learn Map difference\\CAE_Model(64)_MapLearning\\epoch_30_MSE.pth\")\n",
    "model = CAE()\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abd2a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (inputs,targets) in enumerate(test_loader):\n",
    "        encon = model.encoder(inputs)\n",
    "        recon = model.decoder(encon)        \n",
    "        for index,xxx in enumerate(recon):\n",
    "            original_x = inputs[index]\n",
    "            reconstr_x = xxx\n",
    "            target_x = targets[index]\n",
    "            image1 = tensor_to_PIL(original_x)\n",
    "            image2 = tensor_to_PIL(reconstr_x)\n",
    "            image3 =  tensor_to_PIL(target_x)\n",
    "            path1 =  'img(ori)MSE/patch_{num}_original(test).png'.format(num=idx*256+index)\n",
    "            path2 =  'img(recon)MSE/patch_{num}_reconstruct(test).png'.format(num=idx*256+index)\n",
    "            path3 =  'img(target)MSE/patch_{num}_target(test).png'.format(num=idx*256+index)\n",
    "            \n",
    "            image1.save(path1)\n",
    "            image2.save(path2)  \n",
    "            image3.save(path3)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for (inputs,targets) in train_loader:\n",
    "        img = inputs\n",
    "        img = img.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "        outputs = model(img)\n",
    "#         # Compute loss\n",
    "        loss = Hube(outputs, targets).to(device)\n",
    "\n",
    "#         # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (data,targets) in test_loader:\n",
    "            img = data\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            targets = targets.to(device)\n",
    "            loss_test = Hube(outputs, targets).to(device)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
